<!DOCTYPE html>
<html lang="en">
<head>
	<title>Snakemake—simple data processing for researchers</title>
	<meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
	<link rel="icon" href="pictures/snakemake_logo.svg" sizes="any" type="image/svg+xml">
	<link rel="stylesheet" href="node_modules/@highlightjs/cdn-assets/styles/github.min.css" type="text/css"/>
	<link rel="stylesheet" href="styles/styles.css">
    <style>
        /* Customize the theme */

		.shower {
			--slide-ratio: calc(16 / 9);
			--color-key: #9b582f;
			--color-white: #eaeaea;
			--slide-notes-max-width: 80ch;
		}


		/* Explicit notes control labels */

		.control {
			--radius: 0.75em;
			--line-height: 1.5em;
		}

		.control input[type='checkbox'] + label::after {
			text-align: center;
			content: "N";
			color: var(--color-off);
		}

		.control input[type='checkbox']:checked + label::after {
			content: "Y";
			color: var(--color-on);
		}
    </style>
</head>
<body class="shower list show-notes">

	<header class="caption">
		<h1>Snakemake—simple data processing for researchers</h1>
		<p><a href="https://blog.liang2.tw/">Liang-Bo Wang</a>, 2022-09-25.</p>
	</header>

	<menu class="control">
		<li class="show-notes">
			<input type="checkbox" id="show-notes-toggle" checked>
			<label for="show-notes-toggle">Slide notes</label>
		</li>
	</menu>

	<!-- Cover Slide -->
	<section id="cover" class="slide clear black">
		<h2 id="talk-header">Snakemake—simple data processing<br>for researchers</h2>
		<p id="talk-info">
			Liang-Bo Wang<br>
			Taipei Bioinformatics Omnibus<br>
			<span style="color: var(--color-black)">2022-09-25</span>
		</p>
		<p id="usage-instr">
			<kbd>Esc</kbd> or swipe up<br>with three fingers to exit<br>
			<kbd>←</kbd> <kbd>→</kbd> to navigate<br>
			<a rel="license" href="http://creativecommons.org/licenses/by/4.0/">
				<img alt="Creative Commons Attribution 4.0 International License"
					src="pictures/cc-by-4.0.svg"/>
			</a>
		</p>
		<figure>
			<img src="pictures/donggeun-lee-BpWvu_KLJxo-unsplash.jpg" class="cover w" alt="">
			<figcaption class="copyright bottom white">
				Photo by <a href="https://unsplash.com/@dizy64">DongGeun Lee</a>
				on <a href="https://unsplash.com/photos/BpWvu_KLJxo">Unsplash</a>
			</figcaption>
		</figure>
		<style>
			#talk-header, #talk-info {
				text-align: center;
				position: absolute;
				color: var(--color-white);
				margin: 0;
			}
			#talk-header {
				font-size: 3rem;
				font-weight: 600;
				line-height: 1.25;
				top: 6rem;
				/* CSS Gradient https://cssgradient.io/ */
				background-image: linear-gradient(
					to right,
					#9b582f8f 0%,
					#4f453c8e 100%
				);
				left: 0;
				right: 0;
				padding: 1.25em calc(var(--slide-left-side) / 2);
			}
			#talk-info {
				left: var(--slide-left-side);
				right: var(--slide-right-side);
				font-size: 1.5rem;
				line-height: 1.5;
				bottom: 4rem;
			}
			#cover .copyright {
				left: calc(var(--slide-left-side) / 2);
			}
			#usage-instr {
				color: var(--color-white);
				font-size: 1rem;
				line-height: 1.75;
				right: calc(var(--slide-right-side) / 2);
				bottom: 20px;
				position: absolute;
				text-align: right;
				margin: 0;
			}
			#usage-instr a[rel="license"] {
				background-image: none;
			}
			#usage-instr a[rel="license"] img {
				height: 1em;
				color: var(--color-white);
			}
			#usage-instr kbd {
				color: var(--color-black);
				background-color: var(--color-light);
			}
		</style>
	</section>

	<section id="target-audience" class="slide">
		<h2>This talk is for researchers who need to automate things in a handy way</h2>
		<div class="two columns l67">
			<ul>
				<li>Some advice may not apply to a bioinformatics core lab, who develop pipelines as their main job</li>
				<li class="next">This is <em>not</em> a complete Snakemake tutorial;<br>
					please learn it properly from the <a href="https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html">official tutorial</a></li>
				<li class="next">I will share my experience of Snakemake and how to best utilize it</li>
			</ul>
			<figure>
				<img
					class="fill w"
					src="pictures/beesy_researcher_DALL·E.png"
					alt="DALL·E generated art using the prompt 'a hard-working bee working on multiple tasks, digital illustration'">
				<figcaption class="citation right">A bee-sy dry-lab researcher</figcaption>
			</figure>
		</div>
	</section>

	<section class="slide-notes">
		<h3>How to learn Snakemake from scratch using official materials?</h3>
		<ol>
			<li>Go through the official tutorial and best practices</li>
			<li>You are probably ready to implement your own pipeline</li>
			<li>If you need to run Snakemake on HPC or a cloud, go through the executor tutorial and the documentation about the cluster/cloud execution</li>
			<li>Check out the rest of the documentation once you get a better understanding of Snakemake</li>
			<li>Keep an eye on Snakemake's changelog for new features</li>
		</ol>
	</section>

	<section id="about-me" class="slide">
		<h2>About me</h2>
		<div class="two columns r33">
			<ul>
				<li>PhD in Computational and Systems Biology<br>
					from Washington University in St. Louis</li>
				<li>My thesis focuses on cancer genomics</li>
				<li>Worked in related consortia including
					<a href="https://proteomics.cancer.gov/programs/cptac">CPTAC</a>,
					<a href="https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga">TCGA</a>,
					and <a href="https://humantumoratlas.org/">HTAN</a>
					with thousands of samples
				</li>
				<li>Common tasks as a researcher: prototyping new tools/pipelines, data wrangling, and analyses</li>
			</ul>
		</div>
		<img
			class="fill h place r"
			src="pictures/my_protrait.jpg"
			alt="My protrait">
		<style>
			#about-me abbr {
				font-variant-caps: normal;
			}
		</style>
	</section>

	<section id="scenarios" class="slide tight">
		<h2>My top needs for a pipeline/workflow</h2>
		<div class="two columns">
			<div>
				<p>To process multiple samples on different computing platforms</p>
				<figure>
					<img class="fill w"
						src="pictures/scenario-data-processing_DALL·E.png"
						alt="DALL·E generated art using the prompt 'four repeats in a two by two grid of a robot assembling car parts on a conveyor belt, digital art'">
				</figure>
			</div>
			<div>
				<p>To reproduce my analysis steps and results</p>
				<figure>
					<img class="fill w"
						src="pictures/secnario-reproducible-analysis_DALL·E.png"
						alt="DALL·E generated art using the prompt 'a robot arm handling multiple sheets of papers with scientific charts and illustrations on a wood table, digital art'">
				</figure>
			</div>
		</div>
		<style>
			#scenarios figure {
				width: 20rem;
				margin-top: 0.5em;
			}
		</style>
	</section>

	<section id="scenario-data-processing" class="slide">
		<h2>Scenario 1: A pipeline to process multiple samples on different computing platforms</h2>
		<div class="two columns l67">
			<ul>
				<li>Run in different environments: standalone server, <abbr title="High-Performance Computing">HPC</abbr> cluster, and cloud</li>
				<li>HPC cluster has its own job queue and computing architecture (<a href="https://en.wikipedia.org/wiki/IBM_Spectrum_LSF">LSF</a> at my school)</li>
				<li>We use public cloud services (Google and Amazon cloud) and we manage the usage ourselves</li>
			</ul>
			<figure>
				<img
					class="fill w"
					src="pictures/scenario-data-processing_DALL·E.png"
					alt="Illustration of the scenario of a reproducible analysis workflow. DALL·E generated art.">
			</figure>
		</div>
		<style>
			#scenario-data-processing figure {
				margin-top: 0.5em;
			}
		</style>
	</section>

	<section id="scenario-reproducible-analysis" class="slide">
		<h2>Scenario 2: A workflow to reproduce my analysis steps and results</h2>
		<div class="two columns l67">
			<ul>
				<li>Steps to build the dataset for downstream analysis</li>
				<li>Figure generation in the manuscript</li>
				<li>Update results when new data comes in</li>
				<li>Preferably, others can easily set up the workflow and reproduce in an unknown environment</li>
			</ul>
			<figure>
				<img
					class="fill w"
					src="pictures/secnario-reproducible-analysis_DALL·E.png"
					alt="Illustration of the scenario of a reproducible analysis workflow. DALL·E generated art.">
			</figure>
		</div>
		<style>
			#scenario-reproducible-analysis figure {
				margin-top: 0.5em;
			}
		</style>
	</section>

	<section id="scenario-comparison" class="slide tight">
		<table>
			<thead>
				<tr>
					<th></th>
					<th scope="col">
						<img
						src="pictures/scenario-data-processing_DALL·E.png"
						alt="Illustration of the scenario of a reproducible analysis workflow. DALL·E generated art."><br>
						Data processing
					</th>
					<th scope="col">
						<img
						src="pictures/secnario-reproducible-analysis_DALL·E.png"
						alt="Illustration of the scenario of a reproducible analysis workflow. DALL·E generated art."><br>
						Reproducible analysis
					</th>
				</tr>
			</thead>
			<tbody>
				<tr>
					<th scope="row">Inputs</th>
					<td>Lots of samples</td>
					<td>Mostly the same inputs</td>
				</tr>
				<tr>
					<th scope="row">Run type</th>
					<td>Once per sample</td>
					<td>Multiple times</td>
				</tr>
				<tr>
					<th scope="row">Workflow stability</th>
					<td>Stable</td>
					<td>Subject to change</td>
				</tr>
				<tr>
					<th scope="row">Computing environment</th>
					<td>Known and multiple<br>
						Local, HPC, and cloud</td>
					<td>Known and limited*<br>
						Mostly local</td>
				</tr>
			</tbody>
		</table>
		<style>
			#scenario-comparison img {
				height: 7em;
			}
		</style>
	</section>

	<section class="slide-notes">
		<p>
			There are quite a few completely opposite properties about these two scenarios, which are listed in the table.
		</p>
		<p>
			For the reproducible analysis scenario, the computing environment is known and limited only when we try to reproduce it on our own machines.
			In my experience, having a clear and simple instructions is easier for other researchers to work with the analysis than say a fully automated and dockerized setup.
		</p>
	</section>

	<section id="what-is-snakemake" class="slide tight">
		<img src="pictures/snakemake_logo.svg" alt="Logo of Snakemake">
		<h2>What is Snakemake?</h2>
		<p><a href="https://snakemake.github.io/">Snakemake</a> is a Python-based workflow management tool.<br>
			A Snakemake workflow contains a set of <strong>rules</strong>:</p>
		<ul>
			<li>A rule describes how to create output file patterns from input file patterns</li>
			<li>The workflow file runs like a Python script</li>
			<li>Can import external Python libraries</li>
			<li>Can create one's own Python functions</li>
		</ul>
		<style>
			#what-is-snakemake {
				padding-top: 82px;
			}
			#what-is-snakemake img {
				float: right;
				width: 4em;
			}
		</style>
	</section>

	<section id="how-snakemake-works" class="slide tight">
		<h2>How Snakemake works in general</h2>
		<figure>
			<img src="pictures/example-dag.svg" alt="Example job dependency graph">
			<figcaption class="citation">An example task<br>dependency graph</figcaption>
		</figure>
		<p><mark>Trace the workflow <strong>backwards</strong></mark>. Snakemake starts with the rule that generates the final outputs:</p>
		<ol class="next">
			<li>If all the inputs of this rule exist, it's ready to run its commands<br>
				(create a new task)</li>
			<li>If some inputs do not exist, find other rules to generate the required input files (create a dependent task)</li>
			<li>Repeat the process until all outputs can be generated from existing files (complete a task dependency graph)</li>
			<li>Snakemake will start running the corresponding commands/tasks</li>
		</ol>
		<style>
			#how-snakemake-works figure {
				float: right;
				margin-left: 0.5em;
			}
		</style>
	</section>

	<section class="slide-notes">
		<p>
			The task dependency graph has the property as a directed acyclic graph (DAG).
			For Snakemake, such graph is constructed backwards from the final outputs, also known as the pull-based approach.
		</p>
		<p>
			Reading the pipeline backwards can be a bit counterintuitive at first.
			My tip is to always start with the final outputs (usually at the end of the file) and trace the workflow backwards.
		</p>
	</section>

	<section id="snakemake-in-action" class="slide tight">
		<figure class="place bottom right">
			<img class="fill w"
				src="pictures/rna_pipeline_repo_screenshot.png"
				alt="Screenshot of the README of the example pipeline">
			<figcaption class="citation">Screenshot of the pipeline README</figcaption>
		</figure>
		<h2>A simple RNA-seq pipeline in action</h2>
		<p>Calculate gene read counts from RNA-seq BAMs</p>
		<ol>
			<li>Find the local path of the sample BAMs</li>
			<li>Generate read counts (featureCounts)</li>
			<li>Clean up and compress the outputs</li>
			<li>Calculate FPKM and FPKM-UQ values</li>
		</ol>
		<p>Full pipeline <a href="https://github.com/ding-lab/cptac_rna_expression">here</a></p>
		<style>
			#snakemake-in-action figure {
				width: 25rem;
				right: 1rem;
				bottom: 1rem;
			}
		</style>
	</section>

	<section class="slide-notes">
		<p>I implemented two RNA-seq pipelines in Snakemake that are lossly based on <abbr title="NCI Genomic Data Commons">GDC</abbr>'s <a href="https://docs.gdc.cancer.gov/Data/Bioinformatics_Pipelines/Expression_mRNA_Pipeline/">mRNA analysis pipeline</a>:</p>
		<ul>
			<li><a href="https://github.com/ding-lab/cptac_rna_expression">https://github.com/ding-lab/cptac_rna_expression</a> that starts from GDC aligned BAMs</li>
			<li><a href="https://github.com/ding-lab/HTAN_bulkRNA_expression">https://github.com/ding-lab/HTAN_bulkRNA_expression</a> that starts from FASTQs</li>
		</ul>
		<p>
			These pipelines were developed a while ago, when some of my computing environments were quite old and limited.
			So I took a relative conservative approach by using minimal features and very few dependencies (just the Python standard library).
			These pipelines can certainly be improved to better conform to the community's best practices.
			With the ubiquitous conda and Docker support and new Snakemake features, some possible improvements include:
		</p>
		<ul>
			<li>Replace <code>{WORKFLOW_ROOT}</code> with <code>workflow.source_path()</code></li>
			<li>Use pandas to process data frames</li>
			<li>Modularization, though my pipelines are very short (less than 300 lines)</li>
		</ul>
		</section>

	<section id="example-rule" class="slide tight">
		<pre class="language-snakemake">
<code>rule readcount:
    output: count_tsv='readcount/{sample}.tsv'
    input: bam='inputs/{sample}.bam',
		   bai='inputs/{sample}.bam.bai'
    log: 'logs/readcount/{sample}.log'
    params: gtf=GENE_GTF_PTH
    threads: 16
    shell:
        'featureCounts -T {threads} -a {params.gtf} ...'
        '-o {output.count_tsv} {input.bam} 2> {log}'</code>
		</pre>
		<p class="notes next"><code>{sample}</code> is a wildcard whose value is determined by matching the output patterns</p>
		<style>
			#example-rule .notes {
				position: absolute;
				right: 5rem;
				top: 8rem;
				width: 14rem;
				font-size: 1rem;
				margin: 0;
				padding: 0.5em;
				border: solid 2px var(--color-key);

			}
			#example-rule .notes code {
				background-color: var(--color-yellow);
			}
		</style>
	</section>

	<section id="example-notes" class="slide-notes">
		<p>
			If you have wrote a <a href="https://en.wikipedia.org/wiki/Make_(software)#Makefile">Makefile</a> before, snakemake rules share the same spirit as a Makefile's rule.
			And they run in a similar way.
		</p>
		<h3>Snakemake syntax explained</h3>
		<dl>
			<dt><code>{sample}</code></dt>
			<dd>
				Known as <a href="https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html#wildcards">wildcards</a> that matches the output file pattern with the existing files.
			</dd>
			<dt><code>input:</code>, <code>output:</code></dt>
			<dd>File patterns for inputs and outputs. Use key-value pairs <code><strong>key</strong>='...'</code> when there are multiple patterns. They are just Python strings and thus can be referred elsewhere by <code>rules.<strong>myrule</strong>.output.<strong>key</strong></code>.</dd>
			<dt><code>shell:</code></dt>
			<dd>The command that will run in a bash shell to generate the desired outputs.</dd>
		</dl>
		<p>Check out the <a href="https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html">documentation</a> for the rest parts of the rule.</p>
		<h3>How snakemake creates a task</h3>
		<p>
			Due to the way snakemake executes, it's easier to resolve the output first by realizing all the wildcard variables.
			Then expand the rest of the rule (inputs, parameters, and etc.)
		</p>
		<p>
			For example, to generate <code>readcount/<mark>my_sample_a</mark>.tsv</code> using this task, <code>{sample}</code> expands to <code>my_sample_a</code> in the rest parts of the rule.
			So Snakemake will look for the corresponding inputs and run the following shell commands:
		</p>
		<pre class="language-shell">
<code>featureCounts -T 16 -a /path/to/genes.gtf \
	-o readcount/my_sample_a.tsv \
	inputs/my_sample_a.bam \
	2> logs/readcount/my_sample_a.log</code>
		</pre>

		<h3>Process multiple samples using <code>snakemake all</code></h3>
		<p>
			To make the pipeline more extensible, use a run-all rule and <a href="https://snakemake.readthedocs.io/en/stable/snakefiles/configuration.html">a config file</a> to process all samples of a batch.
			As shown here, we obtain the list of samples to process from config file by
			reading in the list from the file at <code>config['sample_list']</code>.
			In this case, <code>SAMPLES</code> is a Python list of <code>["my_sample_a", "my_sample_b", ..., "my_sample_d"]</code>.
			In the <code>all</code> rule, we use a Snakemake function <a href="https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html#the-expand-function"><code>expand()</code></a> to generates all the output targets by "filling in" the wildcards of the output pattern using every value of <code>SAMPLES</code>.
		</p>

		<h3>Other commonly used features</h3>
		<p>
			When the simple string pattern matching is not enough, Snakemake also allows many parts of the rule to be determined by Python functions, including <code>input</code>, <code>params</code>, and <code>resources</code>.
			These functions are known as <a href="https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html#input-functions-and-unpack">input functions</a> in Snakemake's documentation.
			They make the rule more flexible.
			As shown here, different samples may have their input files at different locations.
			The same task will ask for more memory if it has been failed before.
		</p>
		<p>
			<a href="https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html#input-functions-and-unpack"><code>unpack()</code></a> is a helper function to automatically unpack the return value of the input function.
			So a function can return multiple key-value pairs.
		<p>
			<code>file_map_df</code> is a pandas DataFrame object loaded from the tabular file specified by the config (<code>config["file_map"]</code>).
		</p>
		<style>
			#example-notes {
				grid-row-end: span 3;
			}
		</style>
	</section>

	<section id="example-execution" class="slide tight">
		<pre class="language-bash">
<code>$ snakemake -j 32 readcount/my_sample_{a,b,c,d}.tsv
# featureCounts ... inputs/my_sample_a.bam
# featureCounts ... inputs/my_sample_b.bam
# ... (two jobs in parallel)</code>
		</pre>
		<div class="next">
			<p>Alternatively, add a run-all rule to <code>snakemake all</code>:</p>
			<pre class="language-snakemake">
<code>with open(config['sample_list']) as f:
	SAMPLES = f.read().splitlines()
rule all:
	input: expand(rules.readcount.output.count_tsv, \
				  sample=SAMPLES)</code>
			</pre>
		</div>
	</section>

	<section id="example-rule-extended" class="slide tight">
		<p>Other powerful features that extend the wildcard file pattern matching:</p>
		<pre class="language-snakemake">
<code>rule readcount:
	output: count_tsv='readcount/{sample}.tsv'
    input: unpack(find_bam_path)  # provides input.bam and input.bai
    resources:  # dynamic resource allocation
		mem_mb=lambda wildcards, attempt: \
			16000 + 16000 * (attempt - 1)  # retry with more memory
	...
def find_bam_path(wildcards):
	# Retrieve local paths using the file map from config (a DataFrame)
	bam_pth = file_map_df.at[wildcards.sample, "rna_genomic_bam_pth"]
	return {'bam': bam_pth,
			'bai': bam_pth + '.bai'}</code>
		</pre>
		<style>
			#example-rule-extended pre code {
				font-size: 18px;
			}
		</style>
	</section>

	<section id="things-i-like" class="slide tight">
		<h2>Things I like about Snakemake</h2>
		<ul>
			<li><strong>Task definition and execution are separated</strong>
				<ul>
					<li>Maximally utilize the available computing resources (CPUs and memory)</li>
					<li>Smart re-run on only the incomplete tasks (for iterative development)</li>
					<li>Integration with external job schedulers (e.g., HPC and Kubernetes)</li>
				</ul>
			</li>
			<li class="next"><strong>Powerful and easy-to-use features</strong>
				<ul>
					<li>Flexible rules by custom Python functions</li>
					<li>Temporary and piped outputs</li>
					<li>Package management (conda),
						containerization (docker),
						and tool wrappers</li>
					<li>New features are <a href="https://snakemake.readthedocs.io/en/stable/project_info/history.html">constantly being introduced</a></li>
				</ul>
			</li>
		</ul>
	</section>

	<section class="slide-notes">
		<p>I want to mention the dry run mode is very useful too (<code>snakemake -n</code>).</p>
	</section>

	<section id="things-i-dont-like" class="slide tight">
		<h2>Things I don't like about Snakemake</h2>
		<ul>
			<li>Running large number of tasks (> 100k) can be slow/fragile</li>
			<li class="next">Flexible features can be a double-edged sword; not the most robust
				<ul>
					<li>Unique combinations of features can trigger weird bugs or crash the runtime</li>
					<li>Though bugs are usually fixed eventually, it may take up too much of the development time for a researcher</li>
				</ul>
			</li>
			<li class="next">Running on a cloud comes with large setup/runtime overhead
				<ul>
					<li>All files need to be tracked (e.g., inputs, outputs, and references)</li>
					<li>Overhead in downloading/uploading files and setting up the environment</li>
					<li>No one simple workflow for all setups; require optimization</li>
				</ul>
			</li>
		</ul>
	</section>

	<section id="best-practices-for-data-processing" class="slide tight">
		<img
			class="illustration place top right"
			src="pictures/scenario-data-processing_DALL·E.png"
			alt="Illustration of the scenario of a reproducible analysis workflow. DALL·E generated art.">
		<h2>My best practices for data processing</h2>
		<ul>
			<li>Process samples in batches; use config file</li>
			<li>Use file checksums to track upstream sources and outputs</li>
			<li>Start with a big fat Docker/conda environment that contains all dependencies*</li>
			<li class="next">Do I really need a "pipeline"? Do I run for 10+ times? <br>
				Good old bash scripts plus <a href="https://www.gnu.org/software/parallel/sphinx.html">GNU Parallel</a> may be sufficient or more worth the time
			</li>
			<li class="next">Running on cloud will be difficult than local/HPC unless there is a team maintaining the cloud infrastructure</li>
		</ul>
		<style>
			#best-practices-for-data-processing .illustration {
				width: 10rem;
			}
		</style>
	</section>

	<section class="slide-notes">
		<h3>How to set up the conda environment or the Docker image?</h3>
		<p>
			I actually had better experience to simply put together all the dependencies in one big fat Docker image or conda environment.
			This setup can live outside Snakemake, so it doesn't take care of pulling the docker image or creating the conda environment.
			This comes with some advantages:
		</p>
		<ul>
			<li>It's easier to debug and learn when one is new to Snakemake</li>
			<li>If one creates a pipeline from scratch, it's likely you will first try out the steps in a conda environment anyway. Then one can re-use the environment</li>
			<li>Some computing environments have very non-standard (broken) ways to use conda and Docker, which breaks Snakemake</li>
		</ul>
		<p>
			However, this approach is against the best practice because it reduce the reusability of the rules and sometimes different rules have incompatible dependencies.
			One should consider switching to a rule-based environments/images later on.
		</p>
	</section>

	<section id="batch-and-config" class="slide tight">
		<h2>Sample batches, config, and file map</h2>
		<div class="two columns">
			<div>
				<pre class="language-bash small">
<code>pipeline_src/
├── scripts/...
└── Snakefile

batch_yyyy-mm-dd/  # from a template
├── config.json
├── sample.list
├── output/...
└── output_manifest.csv</code>
				</pre>
				<pre class="language-bash small next">
<code># Under the batch folder
snakemake --configfile=config.json \
  -s /pipeline_src/Snakefile \
  -j 50 --attempt 3 \
  --resources io_heavy=4 -- \
  all</code>
				</pre>
			</div>
			<div>
				<pre class="language-json small next">
<code>// config.json
{
  "sample_list": "samples.list",
  "file_map": "/path/to/file_map.csv",
  "gtf": "/path/to/my_annotation.gtf",
  ...
}</code>
				</pre>
				<pre class="language-bash small next">
<code># file_map.csv
sample,file_type,local_path,uuid,md5_checksum,...
sample_A,rna_bam,/path/to/sample_A.bam,5415b...
sample_B,rna_bam,/path/to/sample_B.bam,289c7...

# output_manifest.csv
sample,file_type,local_path,md5_checksum,...
sample_A,tsv,/path/to/readcount/sample_A.tsv,...
sample_B,tsv,/path/to/readcount/sample_B.tsv,...</code>
				</pre>
			</div>
		</div>
		<style>
			#batch-and-config .two.columns {
				grid-template-columns: 45% 55%;
				column-gap: 24px;
			}
			#batch-and-config pre,
			#batch-and-config code {
				overflow-x: visible;
			}
			#batch-and-config code {
				width: auto;
			}
			#batch-and-config .small code {
				font-size: 1rem;
				line-height: 1.5;
			}
			#batch-and-config li {
				font-size: 20px;
				line-height: 2;
			}
		</style>
	</section>

	<section class="slide-notes">
		<h3>Advantages of using batch folders, config, file map, and output manifest</h3>
		<p>
			Batch folders make the pipeline source code and the outputs live in different locations.
			Good for version tracking the pipeline and reusing the pipeline.
			We can also create a template folder for new batches.
			Config file is a natural solution to specify the batch-specific parameters.
		</p>
		<p>
			Input file map is useful when the upstream files are tracked externally (say, in a database or some centralized system).
			It also retains the file metadata (e.g. checksums, UUID, experiment details, and other cross-references).
			For example, our lab maintains <a href="https://github.com/ding-lab/CPTAC3.catalog">a file catalog</a> to track all CPTAC data on GDC.
			It also tracks the files we have downloaded to the different storage systems in our lab.
			Thus, our example pipeline looks up this catalog to find the input BAM files.
		</p>
	</section>

	<section id="checksum" class="slide">
		<h2>Checksum for both inputs and outputs</h2>
		<p>Not sure if the file is the same? Verify its <a href="https://en.wikipedia.org/wiki/Checksum">checksum</a>!</p>
		<ul>
			<li>Detect if inputs have changed or corrupted</li>
			<li>Ensure output file integrity</li>
			<li>I generally use MD5 because of its speed, unless there is a security concern</li>
			<li>This can be implemented outside of the pipeline too</li>
		</ul>
	</section>

	<section class="slide-notes">
		<h3>Advantages of using checksums everywhere</h3>
		<p>There are quite a few possible reasons lead to a input change or corruption:</p>
		<ul>
			<li>With increasing data size, it's more likely to get rotten bits from failing storage</li>
			<li>Silent file transfer errors</li>
			<li>Updates from the upstream</li>
		</ul>
		<p>In general, it's a good idea to keep checksums all the time.
			Here is a snippet to generate MD5 checksums of everything under a folder in parallel and verify the content using the generated checksums:</p>
		<pre class="language-bash">
<code>fd --type file --exclude 'README*' --exclude '*CHECKSUMS' \
	| sort \
	| parallel --keep-order -j4 --bar 'md5sum {}' \
	> MD5_CHECKSUMS
md5sum -c MD5_CHECKSUMS</code>
		</pre>
	</section>

	<section id="best-practices-for-reproducible-analysis" class="slide tight">
		<img
			class="illustration place top right"
			src="pictures/secnario-reproducible-analysis_DALL·E.png"
			alt="Illustration of the scenario of a reproducible analysis workflow. DALL·E generated art.">
		<h2>My best practices for reproducible analysis</h2>
		<ul>
			<li>Work on the workflow later when the project is in shape (refactoring takes time)</li>
			<li>Start with making the independent reproducible scripts<br>
				(e.g., R Markdown/Jupyter notebooks)</li>
			<li class="next">Construct the workflow in stages:
				<ol>
					<li>Make a data freeze. Better if it contains a changelog and checksums</li>
					<li>Run the analyses and number them (e.g. <code>09_xxx.Rmd</code>)</li>
					<li>Generate figures/tables/number for publication</li>
				</ol>
			</li>
			<li class="next">Regularly test the workflow</li>
		</ul>
		<style>
			#best-practices-for-reproducible-analysis h2 {
				font-size: 42px;
			}
			#best-practices-for-reproducible-analysis .illustration {
				width: 10rem;
			}
		</style>
	</section>

	<section id="snakemake-vs-cwl-nextflow" class="slide tight">
		<h2>Snakemake vs <abbr title="Common Workflow Language">CWL</abbr>/<abbr title="Workflow Description Language">WDL</abbr> (and Nextflow)</h2>
		<p><a href="https://www.commonwl.org/">CWL</a>, <a href="https://openwdl.org/">WDL</a>, and <a href="https://www.nextflow.io/">Nextflow</a> ...</p>
		<ul>
			<li>Based on an explicit and forward task dependency (push-based <abbr title="Directed Acyclic Graph">DAG</abbr>)</li>
			<li>Generate <strong>unique IDs per workflow run</strong>; useful for large scale processing, monitoring, and integration with <abbr title="Laboratory Information Management System">LIMS</abbr></li>
			<li><strong>Rigorous</strong>, but less flexible and more tedious to write</li>
			<li><strong>Cloud friendly</strong>; support diverse backends</li>
			<li><strong>Ideal for a core lab</strong> and a workflow that will run for 100+ times</li>
			<li>Not very useful for reproducing analyses/figures</li>
		</ul>
		<style>
			#snakemake-vs-cwl-nextflow h2 {
				font-size: 42px;
			}
		</style>
	</section>

	<section id="snakemake-vs-airflow" class="slide">
		<h2>Did someone mention Airflow?</h2>
		<div class="columns two">
			<ul>
				<li>Very few use <a href="https://airflow.apache.org/">Airflow</a> in the field</li>
				<li class="next">Strengths: great workflow monitoring ability; widely used by the big techs</li>
				<li class="next">Weaknesses: hard to set up locally and iterate the dev; requires its own infra (and DevOps); not HPC friendly; lack network effect</li>
			</ul>
			<figure>
				<img class="fill w"
					src="pictures/BenSiranosian-tweet.png"
					alt="Tweet screenshot by @BenSiranosian">
				<figcaption class="citation">
					From <a href="https://twitter.com/BenSiranosian/status/1558631901346164736">@BenSiranosian's tweet</a> and <a href="https://www.bsiranosian.com/bioinformatics/why-are-bioinformatics-workflows-different/">his blog post</a>.
				</figcaption>
			</figure>
		</div>
		<style>
			#date-eng-vs-bioinfo figure {
				text-align: center;
			}
			#date-eng-vs-bioinfo figure img {
				width: 100%;
			}
		</style>
	</section>

	<section id="when-to-use-snakemake" class="slide tight">
		<h2>When to use Snakemake or others?</h2>
		<ul>
			<li>If you already know Python, are new to workflows, or don't develop pipelines for a living, pick Snakemake.</li>
			<li>To make your research results reproducible, also pick Snakemake</li>
			<li class="next">For pipelines that solely run on a cloud, run at a large scale constantly, or require monitoring, pick other solutions:
				<ul>
					<li>CWL is the most popular approach in my community, which is used by <a href="https://github.com/NCI-GDC/gdc-workflow-overview">NCI GDC</a>, <a href="https://terra.bio/">Terra</a>, and my lab/institution. Highly modular and portable</li>
					<li>Nextflow has a strong community promoting and contributing to it. It also maintains a collection of <a href="https://nf-co.re/">off-the-shelf workflows</a></li>
				</ul>
			</li>
		</ul>
	</section>

	<section id="summary" class="slide">
		<h2>Summary</h2>
		<div class="two columns r40">
			<ul>
				<li>Snakemake is an easy-to-learn and versatile workflow management tool, suitable for researchers prototyping and analyses</li>
				<li>Snakemake works by file pattern based rules and backward task dependency</li>
				<li>Best practices: bundle deps by conda/Docker, run in batches and stages, use checksums</li>
			</ul>
			<figure>
				<img class="fill w"
					src="pictures/snakes_and_pipes_DALL·E.png"
					alt="DALL·E generated art using the prompt 'gray concrete wall and floor, multiple colorful anacondas in pipe-like shape in parallel and interconnected, wide shot, 24mm, 4k, photo realistic, golden hour'">
				<figcaption class="citation">Snakemake can be our great buddy of data processing pipelines and reproducible analysis workflows</figcaption>
			</figure>
		</div>
	</section>

	<section id="end" class="slide clear black">
		<h2>Thank You</h2>
		<figure>
			<img src="pictures/donggeun-lee-BpWvu_KLJxo-unsplash.jpg" class="cover w" alt="">
			<figcaption class="copyright bottom white">
				Photo by <a href="https://unsplash.com/@dizy64">DongGeun Lee</a>
				on <a href="https://unsplash.com/photos/BpWvu_KLJxo">Unsplash</a>
			</figcaption>
		</figure>
		<style>
			#end h2 {
				position: absolute;
				bottom: 6rem;
				left: 0;
				right: 0;
				margin: 0;
				padding: 1.25em calc(var(--slide-left-side) / 2);

				font-size: 3rem;
				font-weight: 600;
				line-height: 1.25;
				text-align: center;

				color: var(--color-white);
				background-image: linear-gradient(
					to right,
					#9b582f8f 0%,
					#4f453c8e 100%
				);
			}

			#end .copyright {
				left: calc(var(--slide-left-side) / 2);
			}
		</style>
	</section>

	<div class="progress"></div>

	<!-- GitHub badge -->
	<footer class="badge">
		<a href="https://github.com/ccwang002/2022Talk-snakemake/">
			<svg width="81" height="79" viewBox="0 0 81 79" aria-hidden="true">
				<path d="M40.5 0a40.5 40.5 0 0 0-12.8 78.93c2 .37 2.76-.88 2.76-2s0-3.51-.05-6.89c-11.27 2.45-13.64-5.43-13.64-5.43-1.84-4.68-4.5-5.92-4.5-5.92-3.68-2.51.28-2.46.28-2.46 4.06.29 6.2 4.17 6.2 4.17 3.61 6.19 9.48 4.4 11.79 3.37a8.65 8.65 0 0 1 2.57-5.41c-9-1-18.45-4.5-18.45-20a15.65 15.65 0 0 1 4.17-10.87 14.57 14.57 0 0 1 .4-10.72s3.4-1.09 11.14 4.15a38.39 38.39 0 0 1 20.28 0c7.73-5.24 11.13-4.15 11.13-4.15a14.55 14.55 0 0 1 .4 10.72 15.63 15.63 0 0 1 4.16 10.87c0 15.56-9.47 19-18.49 20 1.45 1.25 2.75 3.72 2.75 7.5v11.11c0 1.08.73 2.34 2.78 1.95A40.51 40.51 0 0 0 40.5 0z"/>
			</svg>
			See related materials<br>
			on GitHub
		</a>
	</footer>

	<script src="node_modules/@shower/core/dist/shower.js"></script>
	<script defer src="node_modules/@highlightjs/cdn-assets/highlight.min.js"></script>
	<script defer src="js/highlightjs-snakemake.js"></script>
	<script>
		document.addEventListener('DOMContentLoaded', (event) => {
			// Display or hide the slide notes
			const body = document.querySelector('body');
			const notesToggle = document.querySelector('.control .show-notes input');
			notesToggle.checked ? body.classList.add('show-notes') : body.classList.remove('show-notes');
			notesToggle.addEventListener('click', (event) => {
				body.classList.toggle('show-notes');
			});

			// Load Highlight.js
			hljs.registerLanguage('snakemake', snakemake);
			hljs.highlightAll();
		});
	</script>
</body>
</html>
